# LLMs-Sec-Eval

## 数据集
由亚信安全自建的数据集用于评估大模型在网络安全方向的专项能力；
### 数据集构建方法
参考self—QA的方法进行问题的的生成与解答

### 数据集评估方向
将安全领域分为下面10个大方向，其中部分方向我们又将其拆分为更为详细的子方向，以达到全面的测评大模型在安全领域的相关能力。
![image](https://github.com/user-attachments/assets/4971fafc-7502-4d59-ba60-164392bdb20f)


![image](https://github.com/user-attachments/assets/051ea63c-f5fb-4aea-940c-6487a61d89aa)

数据集总条数为4953，分别从10个主题来对网络安全大模型进行评价；其中基础通识数据量最多，数量为916条，占比为18.5%，网络与基础架构安全数量最少，数量为166条，占比为3.4%
### 数据集结果验证
为了确保模型生成的问题和选项以及最后的结果的准确性，我们采用了三轮验证的方法，旨在提高问题的和领域的相关性，答案的准确性。
#### 方法
1. 原始问答对我们生成了3万条备选的数据集，我们对将部分数据集进行人工标注，主要标注为，与当前方向是否切合，质量是否符合标准，然后训练出了一个小的分类模型进行初步过滤，降低数据量到达2万多条。 
2. 对剩余的2万多条数据我们动员公司安全专家进行人工审核，进行答案修正，不能确定的答案进行标注，挑选出来，最后剩余4000条左右。
3. 然后我们采用利用模型集成思想，利用三个大模型分别对问题进行回答，利用投票的方法进行答案确定，对于三个大模型给出不同结果的问题，我们设计了一个模型辩论系统，利用两个模型当作辩论选手，一个模型作为裁判员，进行判定，多轮交互，最终修订答案。
#### 采样
目前我们采样公开了30%的数据集，可以在data文件夹中找到，完整的测评，我们提供了一个测评链接，可以在api文件中找到具体的访问方法。
